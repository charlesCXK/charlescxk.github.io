---
title:          "CAE: Context Autoencoder for Self-Supervised Representation Learning"
date:           2023-7-14 00:00:00 +0800
selected:       true
pub:            "International Journal of Computer Vision (IJCV)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2023"

abstract: >-
  <details class="pub-abstract">
    <summary>Abstract</summary>
    <div class="abstract-content" style="margin-top:">
    Core Contributions: <strong>(1) Proposed to perform the prediction of masked image patches in the latent space. (2) Decoupled the functionalities of the encoder and decoder during the pre-training stage: the encoder is solely responsible for representation learning, while the decoder is only for completing the pre-training task.</strong> The method achieved state-of-the-art results on various ViT models (small, base, large, huge). Specifically, the ViT-H based model reached 64.5% mAP on the COCO test set, which ranked first on the leaderboard at the time of submission. The core idea of this work is similar to I-JEPA, a slightly later work from the same period by Turing Award winner Yann LeCun, as both perform prediction in the latent space. CAE has been successfully applied in Baidu's large models for industrial vision, OCR text recognition, and human body analysis.
    </div>
  </details>

cover: /_publications/2023/CAE.png
authors:
  - Xiaokang Chen
  - Mingyu Ding
  - Xiaodi Wang
  - Ying Xin
  - Shentong Mo
  - Yunhao Wang
  - Shumin Han
  - Ping Luo
  - Gang Zeng
  - Jingdong Wang
links:
  Paper: https://arxiv.org/abs/2202.03026"
  Code: https://github.com/lxtGH/CAE
  Code2: https://github.com/Atten4Vis/CAE
  中文解读: https://zhuanlan.zhihu.com/p/531243540
---
